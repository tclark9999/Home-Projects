{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3 (ipykernel)",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.8.10",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat_minor": 2,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "code",
            "source": [
                "import pandas as pd\r\n",
                "import requests\r\n",
                "from bs4 import BeautifulSoup, Comment\r\n",
                "import re\r\n",
                "import time"
            ],
            "metadata": {
                "azdata_cell_guid": "22929b93-d257-439b-a57e-4a9044a2b2b4",
                "language": "python"
            },
            "outputs": [],
            "execution_count": 1
        },
        {
            "cell_type": "code",
            "source": [
                "url = 'https://www.pro-football-reference.com/teams'"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "5ce67f28-38e8-4ac1-bd70-ad8cbc371a37"
            },
            "outputs": [],
            "execution_count": 2
        },
        {
            "cell_type": "code",
            "source": [
                "#Get the urls of all the teams from the team landing page\n",
                "def get_team_urls(main_url,year):\n",
                "    #Get the page\n",
                "    teams_page = requests.get(main_url)\n",
                "    #Beautiful Soup the page\n",
                "    teams_soup = BeautifulSoup(teams_page.content,\"html.parser\")\n",
                "    #Use Beautiful Soup to find the active teams\n",
                "    table_soup = teams_soup.find(id=\"teams_active\")\n",
                "    #Find all table headers (th) with class = \"left\"\n",
                "    elements = table_soup.find_all(\"th\",class_=\"left\")\n",
                "    team_list = []\n",
                "    #Loop over all active teams\n",
                "    for e in elements:\n",
                "        #Get the team urls\n",
                "        link = e.find(\"a\")\n",
                "        base_url = 'https://www.pro-football-reference.com'\n",
                "        if link:\n",
                "            team_list += [base_url + link[\"href\"] + f\"{year}_roster.htm\"]\n",
                "    return team_list"
            ],
            "metadata": {
                "azdata_cell_guid": "e684c752-7a3b-415c-ac35-8fcc0e1141dd",
                "language": "python"
            },
            "outputs": [],
            "execution_count": 3
        },
        {
            "cell_type": "code",
            "source": [
                "def get_player_urls(r_url):\r\n",
                "\r\n",
                "\r\n",
                "    #Get the html for the team\r\n",
                "    roster_page = requests.get(r_url)\r\n",
                "    #Use Beautiful Soup on the HTML content\r\n",
                "    roster_soup = BeautifulSoup(roster_page.content,\"html.parser\")\r\n",
                "    #find the all_roster div\r\n",
                "    roster_div = roster_soup.find(id=\"all_roster\")\r\n",
                "    #prettify the roster html \r\n",
                "    pretty_roster = roster_div.prettify()\r\n",
                "    #Remove all the comments (The seem to add comments to make the scraping harder)\r\n",
                "    roster_no_comments = pretty_roster.replace(\" <!--\",\"\").replace(\"-->\",\"\")\r\n",
                "    player_list = []\r\n",
                "\r\n",
                "    #Use Beautiful soup on the uncommented html\r\n",
                "    new_soup = BeautifulSoup(roster_no_comments,\"html.parser\")\r\n",
                "    #find all the data-stat attributes and get the link the the player page of the gamelog\r\n",
                "    player_elements = new_soup.find_all(attrs={\"data-stat\":\"player\"})\r\n",
                "    base_url = 'https://www.pro-football-reference.com'\r\n",
                "    for player in player_elements:\r\n",
                "        player_a = player.find(\"a\")\r\n",
                "        if player_a:\r\n",
                "            player_list +=[base_url + player_a[\"href\"] + '/gamelog/']\r\n",
                "    return player_list"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "fb43bee4-a26f-4cf0-9892-9153bfa8242a"
            },
            "outputs": [],
            "execution_count": 4
        },
        {
            "cell_type": "code",
            "source": [
                "def get_player_data_frame(play_url):\r\n",
                "    \r\n",
                "    #Pull HTML tables into pandas\r\n",
                "    player_all_df = pd.read_html(play_url)\r\n",
                "    #Use First Table (Regular Season)\r\n",
                "    player_df = player_all_df[0]\r\n",
                "    #Combine Mult-Layer column names\r\n",
                "    player_df.columns = [f'{i}|{j}' if 'Unnamed' not in str(i) else f'{j}' for i,j in player_df.columns]\r\n",
                "\r\n",
                "    #Get html for player page to get player info\r\n",
                "    player_page = requests.get(play_url)\r\n",
                "    #Use Beautiful soup on the html\r\n",
                "    player_soup = BeautifulSoup(player_page.content,'html.parser')\r\n",
                "    #Find id meta for player info\r\n",
                "    player_meta = player_soup.find(id=\"meta\")\r\n",
                "    #Get just the text\r\n",
                "    player_desc =  player_meta.get_text()\r\n",
                "    #Regex search for the player position\r\n",
                "    player_position = re.search('Position:(.*)',player_desc).group(1)\r\n",
                "    #Set player position column\r\n",
                "    player_df['Position'] = player_position\r\n",
                "    #Get just the text for the player name for file\r\n",
                "    player_name = player_soup.h1.span.get_text()\r\n",
                "    return player_df, player_position,player_name"
            ],
            "metadata": {
                "azdata_cell_guid": "a8cfb51f-da1a-43d1-ae3c-b8e5efb46166",
                "language": "python"
            },
            "outputs": [],
            "execution_count": 5
        },
        {
            "cell_type": "code",
            "source": [
                "base_path = fr'C:\\Users\\Tyler\\OneDrive\\Documents'"
            ],
            "metadata": {
                "azdata_cell_guid": "c79b2be8-3f32-4d56-8744-5b0442d258c3",
                "language": "python"
            },
            "outputs": [],
            "execution_count": 6
        },
        {
            "cell_type": "code",
            "source": [
                "import os\r\n",
                "\r\n",
                "time.sleep(5)\r\n",
                "yr=2022\r\n",
                "roster_list = get_team_urls(url,yr)\r\n",
                "time.sleep(5)\r\n",
                "for roster in roster_list:\r\n",
                "\r\n",
                "    time.sleep(5)\r\n",
                "    player_list = get_player_urls(roster)\r\n",
                "\r\n",
                "    for player in player_list:\r\n",
                "        time.sleep(5)\r\n",
                "        player_data, player_pos, player_name = get_player_data_frame(player)\r\n",
                "\r\n",
                "        player_pos = player_pos.strip()\r\n",
                "\r\n",
                "        newpath = fr'{base_path}\\{yr}\\{player_pos}'\r\n",
                "        if not os.path.exists(newpath):\r\n",
                "            os.makedirs(newpath)\r\n",
                "\r\n",
                "        player_data.to_csv(fr\"{newpath}\\{player_name}.csv\")"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "fd7b12a4-94fb-4c2e-b38d-b9601d87ec8f",
                "tags": []
            },
            "outputs": [
                {
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
                        "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m player \u001b[38;5;129;01min\u001b[39;00m player_list:\n\u001b[0;32m     13\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m     player_data, player_pos, player_name \u001b[38;5;241m=\u001b[39m \u001b[43mget_player_data_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplayer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     player_pos \u001b[38;5;241m=\u001b[39m player_pos\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m     18\u001b[0m     newpath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mfr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mplayer_pos\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n",
                        "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36mget_player_data_frame\u001b[1;34m(play_url)\u001b[0m\n\u001b[0;32m     17\u001b[0m player_desc \u001b[38;5;241m=\u001b[39m  player_meta\u001b[38;5;241m.\u001b[39mget_text()\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m#Regex search for the player position\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m player_position \u001b[38;5;241m=\u001b[39m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPosition:(.*)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mplayer_desc\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup\u001b[49m(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m#Set player position column\u001b[39;00m\n\u001b[0;32m     21\u001b[0m player_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPosition\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m player_position\n",
                        "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
                    ],
                    "ename": "AttributeError",
                    "evalue": "'NoneType' object has no attribute 'group'",
                    "output_type": "error"
                }
            ],
            "execution_count": 7
        }
    ]
}